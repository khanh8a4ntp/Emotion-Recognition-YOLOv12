# File: app.py
from flask import Flask, request, jsonify, render_template, send_from_directory
from flask_socketio import SocketIO
import cv2
import numpy as np
import os
import time
import requests
import atexit
from src.model_loader import load_model
from src.emotion_detector import detect_emotion, draw_bounding_box
from config import MODEL_PATH, UPLOADS_DIR, GEMINI_API_KEY
from langdetect import detect, DetectorFactory

# Äáº£m báº£o langdetect cho káº¿t quáº£ á»•n Ä‘á»‹nh
DetectorFactory.seed = 0

app = Flask(__name__)
UPLOAD_FOLDER = 'uploads'
app.config['UPLOAD_FOLDER'] = UPLOAD_FOLDER
socketio = SocketIO(app, async_mode='threading')

# Táº¡o thÆ° má»¥c uploads náº¿u chÆ°a cÃ³
if not os.path.exists(UPLOAD_FOLDER):
    os.makedirs(UPLOAD_FOLDER)

# SocketIO events
@socketio.on('connect')
def handle_connect():
    print('Client connected:', request.sid)

@socketio.on('disconnect')
def handle_disconnect():
    print('Client disconnected:', request.sid)

# Load YOLO model
print("Loading YOLO model...")
try:
    model = load_model(MODEL_PATH)
except Exception as e:
    print(f"Error loading model: {e}")
    exit(1)

# Emotion emojis and colors
EMOTION_EMOJIS = {
    'Anger': 'ğŸ˜¡',
    'Contempt': 'ğŸ˜',
    'Disgust': 'ğŸ¤¢',
    'Fear': 'ğŸ˜±',
    'Happy': 'ğŸ˜‚',
    'Neutral': 'ğŸ˜',
    'Sad': 'ğŸ˜¢',
    'Surprised': 'ğŸ˜²',
    'No face detected': 'â“',
    'Unknown': 'â“'
}

EMOTION_COLORS_CSS = {
    'Happy': 'rgb(0, 255, 0)',
    'Anger': 'rgb(255, 0, 0)',
    'Neutral': 'rgb(0, 0, 255)',
    'Sad': 'rgb(128, 128, 128)',
    'Contempt': 'rgb(255, 255, 0)',
    'Disgust': 'rgb(128, 0, 128)',
    'Fear': 'rgb(255, 165, 0)',
    'Surprised': 'rgb(255, 0, 255)',
    'No face detected': 'rgb(255, 255, 255)',
    'Unknown': 'rgb(255, 255, 255)'
}

EMOTION_COLORS_BGR = {
    'Happy': (0, 255, 0),
    'Anger': (0, 0, 255),
    'Neutral': (255, 0, 0),
    'Sad': (128, 128, 128),
    'Contempt': (0, 255, 255),
    'Disgust': (128, 0, 128),
    'Fear': (0, 165, 255),
    'Surprised': (255, 0, 255),
    'No face detected': (255, 255, 255),
    'Unknown': (255, 255, 255)
}

# Emotion-specific response prompts
EMOTION_PROMPTS = {
    'Happy': {
        'initial': "Haha, trÃ´ng cáº­u vui tháº¿! ğŸ˜„ CÃ³ gÃ¬ hay ho Ä‘ang xáº£y ra khÃ´ng, ká»ƒ tá»› nghe vá»›i! ğŸ‰",
        'tone': "vui váº», nÄƒng Ä‘á»™ng, hay Ä‘Ã¹a, dÃ¹ng nhiá»u emoji nhÆ° ğŸ˜„, ğŸ‰, xÆ°ng hÃ´ 'cáº­u-tá»›'"
    },
    'Anger': {
        'initial': "Ã”i, báº¡n Æ¡i, sao trÃ´ng bá»±c tháº¿? ğŸ˜£ CÃ³ gÃ¬ khÃ´ng á»•n Ã ? NÃ³i mÃ¬nh nghe Ä‘á»ƒ mÃ¬nh giÃºp nha! ğŸ¤—",
        'tone': "tháº¥u hiá»ƒu, dá»‹u dÃ ng, quan tÃ¢m, dÃ¹ng emoji nhÆ° ğŸ¤—, ğŸ˜£, xÆ°ng hÃ´ 'báº¡n-tÃ´i'"
    },
    'Neutral': {
        'initial': "HÃ´m nay cáº­u tháº¿ nÃ o? ğŸ˜Š TrÃ´ng bÃ¬nh thÆ°á»ng tháº¿ nÃ y cháº¯c Ä‘ang chill Ä‘Ãºng khÃ´ng? ğŸŒŸ",
        'tone': "thÃ¢n thiá»‡n, nháº¹ nhÃ ng, tÃ² mÃ², dÃ¹ng emoji nhÆ° ğŸ˜Š, ğŸŒŸ, xÆ°ng hÃ´ 'cáº­u-tá»›'"
    },
    'Sad': {
        'initial': "Cáº­u Æ¡i, sao trÃ´ng buá»“n tháº¿? ğŸ˜¢ CÃ³ chuyá»‡n gÃ¬ háº£? Tá»› á»Ÿ Ä‘Ã¢y nÃ¨, ká»ƒ tá»› nghe Ä‘i! ğŸ’–",
        'tone': "an á»§i, áº¥m Ã¡p, quan tÃ¢m, dÃ¹ng emoji nhÆ° ğŸ’–, ğŸ˜¢, xÆ°ng hÃ´ 'cáº­u-tá»›'"
    },
    'Contempt': {
        'initial': "Há»«m, báº¡n Ä‘ang khÃ´ng vui gÃ¬ Ä‘Ãºng khÃ´ng? ğŸ˜ CÃ³ gÃ¬ phiá»n lÃ²ng Ã ? MÃ¬nh muá»‘n nghe báº¡n ká»ƒ láº¯m! ğŸ¤”",
        'tone': "tÃ² mÃ², nháº¹ nhÃ ng, quan tÃ¢m, dÃ¹ng emoji nhÆ° ğŸ¤”, ğŸ˜, xÆ°ng hÃ´ 'báº¡n-tÃ´i'"
    },
    'Disgust': {
        'initial': "Eo, trÃ´ng cáº­u ghÃ©t gÃ¬ láº¯m háº£? ğŸ¤¢ CÃ³ chuyá»‡n gÃ¬ khÃ³ chá»‹u Ã ? Ká»ƒ tá»› xem nÃ o! ğŸ˜£",
        'tone': "tháº¥u hiá»ƒu, tÃ² mÃ², quan tÃ¢m, dÃ¹ng emoji nhÆ° ğŸ˜£, ğŸ¤¢, xÆ°ng hÃ´ 'cáº­u-tá»›'"
    },
    'Fear': {
        'initial': "Ã”i cáº­u Æ¡i, sao trÃ´ng lo láº¯ng tháº¿? ğŸ˜± CÃ³ gÃ¬ Ä‘Ã¡ng sá»£ háº£? Tá»› á»Ÿ Ä‘Ã¢y vá»›i cáº­u nÃ¨! ğŸ¤—",
        'tone': "an á»§i, báº£o vá»‡, dá»‹u dÃ ng, dÃ¹ng emoji nhÆ° ğŸ¤—, ğŸ˜±, xÆ°ng hÃ´ 'cáº­u-tá»›'"
    },
    'Surprised': {
        'initial': "Woa, cáº­u báº¥t ngá» gÃ¬ mÃ  máº¯t trÃ²n xoe tháº¿? ğŸ˜² CÃ³ gÃ¬ thÃº vá»‹ khÃ´ng, ká»ƒ tá»› nghe nhanh! ğŸ‰",
        'tone': "hÃ o há»©ng, tÃ² mÃ², vui váº», dÃ¹ng emoji nhÆ° ğŸ‰, ğŸ˜², xÆ°ng hÃ´ 'cáº­u-tá»›'"
    },
    'No face detected': {
        'initial': "Æ , tá»› khÃ´ng tháº¥y cáº­u Ä‘Ã¢u cáº£! ğŸ˜… Cáº­u Ä‘ang trá»‘n háº£? Hiá»‡n máº·t ra ká»ƒ chuyá»‡n vá»›i tá»› Ä‘i! ğŸ˜œ",
        'tone': "vui váº», tÃ² mÃ², Ä‘Ã¹a vui, dÃ¹ng emoji nhÆ° ğŸ˜…, ğŸ˜œ, xÆ°ng hÃ´ 'cáº­u-tá»›'"
    },
    'Unknown': {
        'initial': "Há»­, tá»› chÆ°a Ä‘oÃ¡n Ä‘Æ°á»£c tÃ¢m tráº¡ng cáº­u nÃ¨! ğŸ˜• Cáº­u Ä‘ang nghÄ© gÃ¬, ká»ƒ tá»› nghe vá»›i! ğŸ˜Š",
        'tone': "thÃ¢n thiá»‡n, tÃ² mÃ², nháº¹ nhÃ ng, dÃ¹ng emoji nhÆ° ğŸ˜Š, ğŸ˜•, xÆ°ng hÃ´ 'cáº­u-tá»›'"
    }
}

# English prompts for emotions (for responses in English)
EMOTION_PROMPTS_ENGLISH = {
    'Happy': {
        'initial': "OMG bro, u look so happy! ğŸ˜ Whatâ€™s making u smile like that? Spill the tea! ğŸ‰",
        'tone': "super chill, hype, playful, use lots of emojis like ğŸ˜, ğŸ‰, teencode like 'u', 'bro', 'lol'"
    },
    'Anger': {
        'initial': "Whoa bro, u look kinda pissed! ğŸ˜¤ Whatâ€™s got u so mad? Tell me, I gotchu! ğŸ¤—",
        'tone': "supportive, chill, caring, use emojis like ğŸ¤—, ğŸ˜¤, teencode like 'u', 'gotchu', 'bro'"
    },
    'Neutral': {
        'initial': "Hey bro, u seem chill today! ğŸ˜ Howâ€™s ur day going? Got any fun stuff to share? ğŸŒŸ",
        'tone': "friendly, curious, relaxed, use emojis like ğŸ˜, ğŸŒŸ, teencode like 'u', 'bro', 'ur'"
    },
    'Sad': {
        'initial': "Aww bro, u look so down... ğŸ¥º Whatâ€™s wrong? Iâ€™m here for u, letâ€™s talk! ğŸ’–",
        'tone': "comforting, warm, caring, use emojis like ğŸ’–, ğŸ¥º, teencode like 'u', 'bro', 'letâ€™s'"
    },
    'Contempt': {
        'initial': "Hmm, u look like uâ€™re judging smth! ğŸ˜ Whatâ€™s up? Spill it, Iâ€™m curious! ğŸ¤”",
        'tone': "curious, playful, chill, use emojis like ğŸ¤”, ğŸ˜, teencode like 'u', 'smth', 'bro'"
    },
    'Disgust': {
        'initial': "Eww bro, whatâ€™s making u look so grossed out? ğŸ¤¢ Tell me, I wanna know! ğŸ˜",
        'tone': "curious, playful, chill, use emojis like ğŸ˜, ğŸ¤¢, teencode like 'u', 'wanna', 'bro'"
    },
    'Fear': {
        'initial': "Oh no bro, u look kinda scared! ğŸ˜± Whatâ€™s freaking u out? Iâ€™m here, talk to me! ğŸ¤—",
        'tone': "comforting, protective, chill, use emojis like ğŸ¤—, ğŸ˜±, teencode like 'u', 'bro', 'freaking'"
    },
    'Surprised': {
        'initial': "Whoa bro, u look so shocked! ğŸ˜² Whatâ€™s got u like that? Tell me quick! ğŸ‰",
        'tone': "excited, curious, playful, use emojis like ğŸ‰, ğŸ˜², teencode like 'u', 'bro', 'quick'"
    },
    'No face detected': {
        'initial': "Yo bro, I canâ€™t see u! ğŸ˜… U hiding or what? Show ur face and chat with me! ğŸ˜œ",
        'tone': "playful, curious, chill, use emojis like ğŸ˜…, ğŸ˜œ, teencode like 'u', 'ur', 'bro'"
    },
    'Unknown': {
        'initial': "Hmm, I canâ€™t tell how uâ€™re feeling, bro! ğŸ¤” Whatâ€™s on ur mind? Tell me! ğŸ˜Š",
        'tone': "friendly, curious, chill, use emojis like ğŸ˜Š, ğŸ¤”, teencode like 'u', 'ur', 'bro'"
    }
}

def get_gemini_response(emotion, user_message=None):
    if not GEMINI_API_KEY or GEMINI_API_KEY == "YOUR_ACTUAL_GEMINI_API_KEY":
        print("GEMINI_API_KEY is not set or invalid.")
        return {
            'message': "Tá»› khÃ´ng káº¿t ná»‘i Ä‘Æ°á»£c vá»›i API Gemini... ğŸ˜“ Thá»­ láº¡i sau nha, giá» ká»ƒ tá»› nghe cáº­u Ä‘ang nghÄ© gÃ¬ Ä‘i! ğŸ˜Š",
            'status': 'error'
        }

    # PhÃ¡t hiá»‡n ngÃ´n ngá»¯ cá»§a tin nháº¯n ngÆ°á»i dÃ¹ng
    language = 'vi'  # Máº·c Ä‘á»‹nh lÃ  tiáº¿ng Viá»‡t
    if user_message:
        try:
            language = detect(user_message)
        except Exception as e:
            print(f"Error detecting language: {e}")
            language = 'vi'  # Fallback to Vietnamese if detection fails

    # Chá»n prompt dá»±a trÃªn ngÃ´n ngá»¯
    if language == 'vi':
        prompt_data = EMOTION_PROMPTS.get(emotion, EMOTION_PROMPTS['Neutral'])
        tone = prompt_data['tone']
        initial_message = prompt_data['initial']
        prompt = f"You are a friendly chatbot acting like a close friend. Respond in Vietnamese with a {tone} tone. Use informal language, address the user as 'cáº­u' or 'báº¡n' as specified, and include emojis to make it lively. "
    else:
        prompt_data = EMOTION_PROMPTS_ENGLISH.get(emotion, EMOTION_PROMPTS_ENGLISH['Neutral'])
        tone = prompt_data['tone']
        initial_message = prompt_data['initial']
        prompt = f"You are a friendly chatbot acting like a close friend. Respond in English with a {tone} tone. Use informal language, address the user as 'bro' or 'u', and include emojis to make it lively. Use teencode like 'u', 'ur', 'lol', 'smth', etc. to sound casual and friendly. "

    if user_message:
        prompt += f"The user said: '{user_message}'. Respond to their message naturally, keeping the {tone} tone and addressing them appropriately."
    else:
        prompt += f"Start the conversation with: '{initial_message}'."

    try:
        print(f"Calling Gemini API with prompt: {prompt}")
        response = requests.post(
            "https://generativelanguage.googleapis.com/v1beta/models/gemini-1.5-flash-latest:generateContent",
            headers={"Content-Type": "application/json"},
            json={
                "contents": [{"parts": [{"text": prompt}]}],
                "generationConfig": {
                    "temperature": 0.9,
                    "topK": 40,
                    "topP": 0.95,
                    "maxOutputTokens": 1024,
                }
            },
            params={"key": GEMINI_API_KEY}
        )
        response_data = response.json()
        print(f"Gemini API response: {response_data}")

        if 'error' in response_data:
            print(f"Gemini API error: {response_data['error']}")
            return {
                'message': "Tá»› gáº·p lá»—i khi káº¿t ná»‘i vá»›i API Gemini... ğŸ˜“ Cáº­u ká»ƒ tá»› nghe chuyá»‡n gÃ¬ vui Ä‘i, chá» tá»› thá»­ láº¡i nha! ğŸ˜Š" if language == 'vi' else "Oops, I canâ€™t connect to the API right now... ğŸ˜“ Tell me smth fun while I try again, bro! ğŸ˜Š",
                'status': 'error'
            }

        return {
            'message': response_data['candidates'][0]['content']['parts'][0]['text'],
            'status': 'success'
        }

    except Exception as e:
        print(f"Error calling Gemini API: {e}")
        return {
            'message': "Tá»› gáº·p lá»—i nhá» rá»“i... ğŸ˜… ThÃ´i, cáº­u ká»ƒ tá»› nghe hÃ´m nay tháº¿ nÃ o Ä‘i, tá»› tÃ² mÃ² láº¯m! ğŸ˜œ" if language == 'vi' else "Oops, I hit a lil snag... ğŸ˜… Tell me how ur dayâ€™s going, Iâ€™m super curious! ğŸ˜œ",
            'status': 'error'
        }

# Routes
@app.route('/')
def index():
    print("Rendering index.html...")
    return render_template('index.html')

@app.route('/uploads/<filename>')
def serve_uploaded_file(filename):
    print(f"Serving file: {filename} from {UPLOADS_DIR}")
    return send_from_directory(UPLOADS_DIR, filename)

@app.route('/upload', methods=['GET', 'POST'])
def upload():
    if request.method == 'POST':
        print("Received upload request...")
        if 'file' not in request.files:
            print("Error: No file uploaded")
            return jsonify({'error': 'No file uploaded'}), 400
        
        file = request.files['file']
        confidence_threshold = float(request.form.get('confidence', 0.05))
        print(f"Confidence threshold: {confidence_threshold}")
        if not file.mimetype.startswith('image'):
            print("Error: Not an image file")
            return jsonify({'error': 'Please upload an image file'}), 400
        
        filename = f"upload_{int(time.time())}_{file.filename}"
        file_path = os.path.join(UPLOADS_DIR, filename)
        print(f"Saving uploaded file to: {file_path}")
        file.save(file_path)
        
        print("Reading image...")
        image = cv2.imread(file_path)
        if image is None:
            print("Error: Failed to read image")
            return jsonify({'error': 'Failed to read image'}), 500
        
        print("Detecting emotions...")
        detections = detect_emotion(model, image, confidence_threshold)
        print(f"Detections: {detections}")
        
        print("Drawing bounding boxes...")
        result_image = draw_bounding_box(image.copy(), detections, EMOTION_COLORS_BGR)
        result_image = cv2.cvtColor(result_image, cv2.COLOR_BGR2RGB)
        result_filename = f"result_{filename}"
        result_path = os.path.join(UPLOADS_DIR, result_filename)
        print(f"Saving result image to: {result_path}")
        success = cv2.imwrite(result_path, cv2.cvtColor(result_image, cv2.COLOR_RGB2BGR))
        if not success:
            print("Error: Failed to save result image")
            return jsonify({'error': 'Failed to save result image'}), 500
        
        if not os.path.exists(result_path):
            print("Error: Result image not found after saving")
            return jsonify({'error': 'Result image not found'}), 500
        
        results = [
            {
                'emotion': e,
                'confidence': c,
                'emoji': EMOTION_EMOJIS.get(e, 'â“'),
                'color': EMOTION_COLORS_CSS.get(e, 'rgb(255, 255, 255)')
            } 
            for e, c, _ in detections
        ]
        image_url = f"/uploads/{result_filename}"
        print(f"Sending response: image={image_url}, results={results}")
        return jsonify({'image': image_url, 'results': results})
    else:
        return render_template('upload.html')

@app.route('/capture', methods=['GET', 'POST'])
def capture():
    if request.method == 'POST':
        print("Received capture request...")
        if 'file' not in request.files:
            print("Error: No file uploaded")
            return jsonify({'error': 'No file uploaded'}), 400
        
        file = request.files['file']
        confidence_threshold = float(request.form.get('confidence', 0.05))
        print(f"Confidence threshold: {confidence_threshold}")
        if not file.mimetype.startswith('image'):
            print("Error: Not an image file")
            return jsonify({'error': 'Please upload an image file'}), 400
        
        filename = f"capture_{int(time.time())}.jpg"
        file_path = os.path.join(UPLOADS_DIR, filename)
        print(f"Saving captured file to: {file_path}")
        file.save(file_path)
        
        print("Reading image...")
        image = cv2.imread(file_path)
        if image is None:
            print("Error: Failed to read image")
            return jsonify({'error': 'Failed to read image'}), 500
        
        print("Detecting emotions...")
        detections = detect_emotion(model, image, confidence_threshold)
        print(f"Detections: {detections}")
        
        print("Drawing bounding boxes...")
        result_image = draw_bounding_box(image.copy(), detections, EMOTION_COLORS_BGR)
        result_image = cv2.cvtColor(result_image, cv2.COLOR_BGR2RGB)
        result_filename = f"result_{filename}"
        result_path = os.path.join(UPLOADS_DIR, result_filename)
        print(f"Saving result image to: {result_path}")
        success = cv2.imwrite(result_path, cv2.cvtColor(result_image, cv2.COLOR_RGB2BGR))
        if not success:
            print("Error: Failed to save result image")
            return jsonify({'error': 'Failed to save result image'}), 500
        
        if not os.path.exists(result_path):
            print("Error: Result image not found after saving")
            return jsonify({'error': 'Result image not found'}), 500
        
        results = [
            {
                'emotion': e,
                'confidence': c,
                'emoji': EMOTION_EMOJIS.get(e, 'â“'),
                'color': EMOTION_COLORS_CSS.get(e, 'rgb(255, 255, 255)')
            } 
            for e, c, _ in detections
        ]
        image_url = f"/uploads/{result_filename}"
        print(f"Sending response: image={image_url}, results={results}")
        return jsonify({'image': image_url, 'results': results})
    else:
        return render_template('capture.html')

@app.route('/record', methods=['GET', 'POST'])
def record():
    if request.method == 'POST':
        print("Received record request...")
        if 'file' not in request.files:
            print("Error: No file uploaded")
            return jsonify({'error': 'No file uploaded'}), 400
        
        file = request.files['file']
        confidence_threshold = float(request.form.get('confidence', 0.05))
        print(f"Confidence threshold: {confidence_threshold}")
        if not file.mimetype.startswith('video'):
            print("Error: Not a video file")
            return jsonify({'error': 'Please upload a video file'}), 400
        
        filename = f"record_{int(time.time())}.webm"
        file_path = os.path.join(UPLOADS_DIR, filename)
        print(f"Saving recorded file to: {file_path}")
        file.save(file_path)
        
        print("Processing video...")
        cap = cv2.VideoCapture(file_path)
        if not cap.isOpened():
            print("Error: Failed to open video")
            return jsonify({'error': 'Failed to open video'}), 500
        
        # Láº¥y thÃ´ng tin video
        fps = cap.get(cv2.CAP_PROP_FPS)
        width = int(cap.get(cv2.CAP_PROP_FRAME_WIDTH))
        height = int(cap.get(cv2.CAP_PROP_FRAME_HEIGHT))
        
        # Táº¡o video Ä‘áº§u ra vá»›i codec webm
        result_filename = f"processed_{filename}"
        result_path = os.path.join(UPLOADS_DIR, result_filename)
        fourcc = cv2.VideoWriter_fourcc(*'VP80')
        out = cv2.VideoWriter(result_path, fourcc, fps, (width, height))
        if not out.isOpened():
            cap.release()
            print("Error: Failed to create output video")
            return jsonify({'error': 'Failed to create output video'}), 500
        
        # Xá»­ lÃ½ tá»«ng frame vÃ  váº½ bounding box
        emotions = {}
        frame_count = 0
        while cap.isOpened():
            ret, frame = cap.read()
            if not ret:
                break
            if frame_count % 30 == 0:
                detections = detect_emotion(model, frame, confidence_threshold)
                for e, c, _ in detections:
                    emotions[e] = max(emotions.get(e, 0), c)
                result_frame = draw_bounding_box(frame.copy(), detections, EMOTION_COLORS_BGR)
                out.write(result_frame)
            else:
                out.write(frame)
            frame_count += 1
        
        cap.release()
        out.release()
        
        if not os.path.exists(result_path):
            print("Error: Processed video not found")
            return jsonify({'error': 'Processed video not found'}), 500
        
        results = [
            {
                'emotion': e,
                'confidence': c,
                'emoji': EMOTION_EMOJIS.get(e, 'â“'),
                'color': EMOTION_COLORS_CSS.get(e, 'rgb(255, 255, 255)')
            }
            for e, c in emotions.items()
        ]
        
        video_url = f"/uploads/{result_filename}"
        print(f"Sending response: video={video_url}, results={results}")
        return jsonify({'video': video_url, 'results': results})
    else:
        return render_template('record.html')

@app.route('/realtime', methods=['GET'])
def realtime():
    return render_template('realtime.html')

@socketio.on('frame')
def handle_frame(data):
    print("Received frame from webcam...")
    confidence_threshold = data.get('confidence', 0.3)
    print(f"Confidence threshold: {confidence_threshold}")
    image_data = np.frombuffer(data['image'], np.uint8)
    frame = cv2.imdecode(image_data, cv2.IMREAD_COLOR)
    
    if frame is None:
        print("Error: Invalid frame received")
        socketio.emit('result_frame', {
            'error': 'Invalid frame',
            'results': [{'emotion': 'Error', 'confidence': 0.0, 'emoji': 'â“', 'color': 'rgb(255, 0, 0)'}],
            'fps': 0
        })
        return
    
    print(f"Frame shape: {frame.shape}")
    detections = detect_emotion(model, frame, confidence_threshold)
    print(f"Detections: {detections}")
    
    results = [
        {
            'emotion': e,
            'confidence': c,
            'emoji': EMOTION_EMOJIS.get(e, 'â“'),
            'color': EMOTION_COLORS_CSS.get(e, 'rgb(255, 255, 255)'),
            'bbox': [int(x1), int(y1), int(x2), int(y2)]
        } 
        for e, c, (x1, y1, x2, y2) in detections
    ]
    
    if not results:
        results = [{
            'emotion': 'No face detected',
            'confidence': 0.0,
            'emoji': EMOTION_EMOJIS['No face detected'],
            'color': EMOTION_COLORS_CSS['No face detected'],
            'bbox': [0, 0, 0, 0]
        }]
    
    primary_emotion = max(results, key=lambda x: x['confidence'])['emotion'] if results else 'No face detected'
    
    print(f"Sending detection results: {results}")
    socketio.emit('result_frame', {
        'results': results,
        'fps': data.get('fps', 0),
        'primary_emotion': primary_emotion
    })

@socketio.on('chat_message')
def handle_chat_message(data):
    print("Received chat message:", data)
    user_message = data.get('message')
    emotion = data.get('emotion', 'Neutral')
    
    socketio.emit('chat_responding', {'status': 'responding'})
    bot_response = get_gemini_response(emotion, user_message)
    
    socketio.emit('chat_response', bot_response)

@app.after_request
def add_header(response):
    response.headers['Cache-Control'] = 'no-cache, no-store, must-revalidate'
    response.headers['Pragma'] = 'no-cache'
    response.headers['Expires'] = '0'
    return response

if __name__ == '__main__':
    print("Starting Flask server...")
    socketio.run(app, debug=True)